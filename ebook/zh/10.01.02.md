## 教你一步一步用c语言实现sift算法、上

参考：Rob Hess维护的sift 库  
环境：windows xp+vc6.0  
条件：c语言实现。  

### 引言：
在我写的关于sift算法的前倆篇文章里头，已经对sift算法有了初步的介绍：[九、图像特征提取与匹配之SIFT算法](http://blog.csdn.net/v_JULY_v/article/details/6186942)，而后在：[九（续）、sift算法的编译与实现](http://blog.csdn.net/v_JULY_v/article/details/6225117)里，我也简单记录下了如何利用opencv，gsl等库编译运行sift程序。

但据一朋友表示，是否能用c语言实现sift算法，同时，尽量不用到opencv，gsl等第三方库之类的东西。而且，Rob Hess维护的sift 库，也不好懂，有的人根本搞不懂是怎么一回事。

那么本文，就教你如何利用c语言一步一步实现sift算法，同时，你也就能真正明白sift算法到底是怎么一回事了。

ok，先看一下，本程序最终运行的效果图，sift 算法分为五个步骤（下文详述），对应以下**第二~第六幅图**：

![](../images/10-1-2/1.jpg)

![](../images/10-1-2/2.jpg)

![](../images/10-1-2/3.jpg)

![](../images/10-1-2/4.jpg)

![](../images/10-1-2/5.jpg)

![](../images/10-1-2/6.jpg)

### sift算法的步骤
要实现一个算法，首先要完全理解这个算法的原理或思想。咱们先来简单了解下，什么叫sift算法：

sift，尺度不变特征转换，是一种电脑视觉的算法用来侦测与描述影像中的局部性特征，它在空间尺度中寻找极值点，并提取出其位置、尺度、旋转不变量，此算法由 David Lowe 在1999年所发表，2004年完善总结。

所谓，Sift算法就是用不同尺度（标准差）的高斯函数对图像进行平滑，然后比较平滑后图像的差别，

差别大的像素就是特征明显的点。

以下是sift算法的五个步骤：
    
#### 一、建立图像尺度空间(或高斯金字塔)，并检测极值点

首先建立尺度空间，要使得图像具有尺度空间不变形，就要建立尺度空间，sift算法采用了高斯函数来建立尺度空间，高斯函数公式为：

![](../images/10-1-2/7.jpg)

上述公式G(x,y,e)，即为尺度可变高斯函数。

而，一个图像的尺度空间L（x,y,e) ,定义为原始图像I(x,y)与上述的一个可变尺度的2维高斯函数G(x,y,e) 卷积运算。

即，原始影像I(x，y)在不同的尺度e下，与高斯函数G(x,y,e)进行卷积，得到L(x,y,e)，如下：
    
![](../images/10-1-2/8.jpg)

以上的（x，y）是空间坐标， e，是尺度坐标，或尺度空间因子，e的大小决定平滑程度，大尺度对应图像的概貌特征，小尺度对应图像的细节特征。大的e值对应粗糙尺度(低分辨率)，反之，对应精细尺度(高分辨率)。

尺度，受e这个参数控制的表示。而不同的L（x,y,e）就构成了尺度空间，具体计算的时候，即使连续的高斯函数，都被离散为（一般为奇数大小）(2\*k+1) \*(2\*k+1)矩阵，来和数字图像进行卷积运算。

随着e的变化，建立起不同的尺度空间，或称之为建立起图像的高斯金字塔。

**但**，像上述L(x,y,e) = G(x,y,e)\*I(x,y)的操作，在进行高斯卷积时，整个图像就要遍历所有的像素进行卷积(边界点除外)，于此，就造成了时间和空间上的很大浪费。

为了更有效的在尺度空间检测到稳定的关键点，也为了缩小时间和空间复杂度，对上述的操作作了一个改建：即，提出了高斯差分尺度空间（DOG scale-space）。利用不同尺度的高斯差分与原始图像I(x,y)相乘 ，卷积生成。

![](../images/10-1-2/9.jpg)

DOG算子计算简单，是尺度归一化的LOG算子的近似。

**ok，耐心点**，咱们再来总结一下上述内容：

1. 高斯卷积  
在组建一组尺度空间后，再组建下一组尺度空间，对上一组尺度空间的最后一幅图像进行二分之一采样，得到下一组尺度空间的第一幅图像，然后进行像建立第一组尺度空间那样的操作，得到第二组尺度空间，公式定义为

    L(x,y,e) = G(x,y,e)\*I(x,y)

    图像金字塔的构建：图像金字塔共O组，每组有S层，下一组的图像由上一组图像降采样得到，效果图，**图A**如下(左为上一组，右为下一组)：
    
    ![](../images/10-1-2/10.jpg)
    
2. 高斯差分  
在尺度空间建立完毕后，为了能够找到稳定的关键点，采用高斯差分的方法来检测那些在局部位置的极值点，即采用俩个相邻的尺度中的图像相减，即公式定义为：
D(x,y,e) = ((G(x,y,ke) - G(x,y,e)) \* I(x,y) = L(x,y,ke) - L(x,y,e)

    效果图，图B：
    
    ![](../images/10-1-2/11.jpg)
    
SIFT的精妙之处在于采用图像金字塔的方法解决这一问题，我们可以把两幅图像想象成是连续的，分别以它们作为底面作四棱锥，就像金字塔，那么每一个 截面与原图像相似，那么两个金字塔中必然会有包含大小一致的物体的无穷个截面，但应用只能是离散的，所以我们只能构造有限层，层数越多当然越好，但处理时 间会相应增加，层数太少不行，因为向下采样的截面中可能找不到尺寸大小一致的两个物体的图像。

#### 咱们再来具体阐述下构造D(x,y,e)的详细步骤：

1. 首先采用不同尺度因子的高斯核对图像进行卷积以得到图像的不同尺度空间，将这一组图像作为金子塔图像的第一层。
2. 接着对第一层图像中的2倍尺度图像（相对于该层第一幅图像的2倍尺度）以2倍像素距离进行下采样来得到金子塔图像的第二层中的第一幅图像，对该图像采用不同尺度因子的高斯核进行卷积，以获得金字塔图像中第二层的一组图像。
3. 再以金字塔图像中第二层中的2倍尺度图像（相对于该层第一幅图像的2倍尺度）以2倍像素距离进行下采样来得到金字塔图像的第三层中的第一幅图像，对该图像采用不同尺度因子的高斯核进行卷积，以获得金字塔图像中第三层的一组图像。这样依次类推，从而获得了金字塔图像的每一层中的一组图像，如下图所示：
    ![](../images/10-1-2/12.jpg)
4. 对上图得到的每一层相邻的高斯图像相减，就得到了高斯差分图像，如下述第一幅图所示。下述第二幅图中的右列显示了将每组中相邻图像相减所生成的高斯差分图像的结果，限于篇幅，图中只给出了第一层和第二层高斯差分图像的计算（下述俩幅图统称为图2）：

    ![](../images/10-1-2/13.jpg)

    ![](../images/10-1-2/14.jpg)
    
    *图像金字塔的建立：对于一幅图像I,建立其在不同尺度(scale)的图像，也成为子八度（octave），这是为了scale-invariant，也就是在任何尺度都能够有对应的特征点，第一个子八度的scale为原图大小，后面每个octave为上一个octave降采样的结果，即原图的1/4（长宽分别减半），构成下一个子八度（高一层金字塔）。*
    
5. 因为高斯差分函数是归一化的高斯拉普拉斯函数的近似，所以可以从高斯差分金字塔分层结构提取出图像中的极值点作为候选的特征点。对DOG 尺度空间每个点与相邻尺度和相邻位置的点逐个进行比较，得到的局部极值位置即为特征点所处的位置和对应的尺度。

#### 二、检测关键点

为了寻找尺度空间的极值点，每一个采样点要和它所有的相邻点比较，看其是否比它的图像域和尺度域的相邻点大或者小。如下图，图3所示，中间的检测点和它同尺度的8个相邻点和上下相邻尺度对应的9×2个点共26个点比较，以确保在尺度空间和二维图像空间都检测到极值点。

![](../images/10-1-2/15.jpg)

因为需要同相邻尺度进行比较，所以在一组高斯差分图像中只能检测到两个尺度的极值点（如上述第二幅图中右图的五角星标识），而其它尺度的极值点检测则需要在图像金字塔的上一层高斯差分图像中进行。依次类推，最终在图像金字塔中不同层的高斯差分图像中完成不同尺度极值的检测。

当然这样产生的极值点并不都是稳定的特征点，因为某些极值点响应较弱，而且DOG算子会产生较强的边缘响应。

#### 三、关键点方向的分配

为了使描述符具有旋转不变性，需要利用图像的局部特征为给每一个关键点分配一个方向。利用关键点邻域像素的梯度及方向分布的特性，可以得到梯度模值和方向如下：

![](../images/10-1-2/16.jpg)

其中，尺度为每个关键点各自所在的尺度。

在以关键点为中心的邻域窗口内采样，并用直方图统计邻域像素的梯度方向。梯度直方图的范围是0～360度，其中每10度一个方向，总共36个方向。

直方图的峰值则代表了该关键点处邻域梯度的主方向，即作为该关键点的方向。

在计算方向直方图时，需要用一个参数等于关键点所在尺度1.5倍的高斯权重窗对方向直方图进行加权，上图中用蓝色的圆形表示，中心处的蓝色较重，表示权值最大，边缘处颜色潜，表示权值小。如下图所示，该示例中为了简化给出了8方向的方向直方图计算结果，实际sift创始人David Lowe的原论文中采用36方向的直方图。

![](../images/10-1-2/17.jpg)

方向直方图的峰值则代表了该特征点处邻域梯度的方向，以直方图中最大值作为该关键点的主方向。为了增强匹配的鲁棒性，只保留峰值大于主方向峰值80％的方向作为该关键点的辅方向。因此，对于同一梯度值的多个峰值的关键点位置，在相同位置和尺度将会有多个关键点被创建但方向不同。仅有15％的关键点被赋予多个方向，但可以明显的提高关键点匹配的稳定性。
        
至此，图像的关键点已检测完毕，每个关键点有三个信息：位置、所处尺度、方向。由此可以确定一个SIFT特征区域。

#### 四、特征点描述符

通过以上步骤，对于每一个关键点，拥有三个信息：位置、尺度以及方向。接下来就是为每个关键点建立一个描述符，使其不随各种变化而改变，比如光照变化、视角变化等等。并且描述符应该有较高的独特性，以便于提高特征点正确匹配的概率。  

首先将坐标轴旋转为关键点的方向，以确保旋转不变性。

![](../images/10-1-2/18.jpg)

接下来以关键点为中心取8×8的窗口。

上图，图5中左部分的中央黑点为当前关键点的位置，每个小格代表关键点邻域所在尺度空间的一个像素，箭头方向代表该像素的梯度方向，箭头长度代表梯度模值，图中蓝色的圈代表高斯加权的范围（越靠近关键点的像素梯度方向信息贡献越大）。

然后在每4×4的小块上计算8个方向的梯度方向直方图，绘制每个梯度方向的累加值，即可形成一个种子点，如图5右部分所示。此图中一个关键点由2×2共4个种子点组成，每个种子点有8个方向向量信息。这种邻域方向性信息联合的思想增强了算法抗噪声的能力，同时对于含有定位误差的特征匹配也提供了较好的容错性。

实际计算过程中，为了增强匹配的稳健性，Lowe建议对每个关键点使用4×4共16个种子点来描述，这样对于一个关键点就可以产生128个数据，即最终形成128维的SIFT特征向量。此时SIFT特征向量已经去除了尺度变化、旋转等几何变形因素的影响，再继续将特征向量的长度归一化，则可以进一步去除光照变化的影响。

#### 五、最后一步

当两幅图像的SIFT特征向量生成后，下一步我们采用关键点特征向量的欧式距离来作为两幅图像中关键点的相似性判定度量。取上图中，**图像A**中的某个关键点，并找出其与**图像B**中欧式距离最近的前两个关键点，在这两个关键点中，如果最近的距离除以次近的距离少于某个比例阈值，则接受这一对匹配点。降低这个比例阈值，SIFT匹配点数目会减少，但更加稳定。关于sift 算法的更多理论介绍请参看此文：<http://blog.csdn.net/abcjennifer/article/details/7639681>。

### sift算法的逐步c实现

ok，上文搅了那么多的理论，如果你没有看懂它，咋办列?没关系，下面，咱们来一步一步实现此sift算法，即使你没有看到上述的理论，慢慢的，你也会明白sift算法到底是怎么一回事，sift算法到底是怎么实现的...。

yeah，请看：

#### 前期工作：

在具体编写核心函数之前，得先做几个前期的准备工作：

1. 头文件：

    ```c
    #ifdef _CH_  
    #pragma package <opencv>  
    #endif  
      
    #ifndef _EiC  
    #include <stdio.h>  
      
    #include "stdlib.h"  
    #include "string.h"   
    #include "malloc.h"   
    #include "math.h"   
    #include <assert.h>  
    #include <ctype.h>  
    #include <time.h>  
    #include <cv.h>  
    #include <cxcore.h>  
    #include <highgui.h>  
    #include <vector>  
    #endif  
      
    #ifdef _EiC  
    #define WIN32  
    #endif  
    ```

2. 定义几个宏，及变量，以免下文函数中，突然冒出一个变量，而您却不知道怎么一回事：
    ```c
    #define NUMSIZE 2  
    #define GAUSSKERN 3.5  
    #define PI 3.14159265358979323846  
      
    //Sigma of base image -- See D.L.'s paper.  
    #define INITSIGMA 0.5  
    //Sigma of each octave -- See D.L.'s paper.  
    #define SIGMA sqrt(3)//1.6//  
      
    //Number of scales per octave.  See D.L.'s paper.  
    #define SCALESPEROCTAVE 2  
    #define MAXOCTAVES 4  
    int     numoctaves;  
      
    #define CONTRAST_THRESHOLD   0.02  
    #define CURVATURE_THRESHOLD  10.0  
    #define DOUBLE_BASE_IMAGE_SIZE 1  
    #define peakRelThresh 0.8  
    #define LEN 128  
      
    // temporary storage  
    CvMemStorage* storage = 0;   
    ```

3. 然后，咱们还得，声明几个变量，以及建几个数据结构（数据结构是一切程序事物的基础麻，:D。）：

    ```c
    //Data structure for a float image.  
    typedef struct ImageSt {        /*金字塔每一层*/  
       
     float levelsigma;  
     int levelsigmalength;  
     float absolute_sigma;  
     CvMat *Level;       //CvMat是OPENCV的矩阵类，其元素可以是图像的象素值         
    } ImageLevels;  
      
    typedef struct ImageSt1 {      /*金字塔每一阶梯*/  
     int row, col;          //Dimensions of image.   
     float subsample;  
     ImageLevels *Octave;                
    } ImageOctaves;  
      
    ImageOctaves *DOGoctaves;        
    //DOG pyr，DOG算子计算简单，是尺度归一化的LoG算子的近似。  
        
    ImageOctaves *mag_thresh ;  
    ImageOctaves *mag_pyr ;  
    ImageOctaves *grad_pyr ;  
      
    //keypoint数据结构，Lists of keypoints are linked by the "next" field.  
    typedef struct KeypointSt   
    {  
     float row, col; /* 反馈回原图像大小，特征点的位置 */  
     float sx,sy;    /* 金字塔中特征点的位置*/  
     int octave,level;/*金字塔中，特征点所在的阶梯、层次*/  
       
     float scale, ori,mag; /*所在层的尺度sigma,主方向orientation (range [-PI,PI])，以及幅值*/  
     float *descrip;       /*特征描述字指针：128维或32维等*/  
     struct KeypointSt *next;/* Pointer to next keypoint in list. */  
    } *Keypoint;  
      
    //定义特征点具体变量  
    Keypoint keypoints=NULL;      //用于临时存储特征点的位置等  
    Keypoint keyDescriptors=NULL; //用于最后的确定特征点以及特征描述字  
    ```
    
4. 声明几个图像的基本处理函数：

    ```c
    CvMat * halfSizeImage(CvMat * im);     //缩小图像：下采样  
    CvMat * doubleSizeImage(CvMat * im);   //扩大图像：最近临方法  
    CvMat * doubleSizeImage2(CvMat * im);  //扩大图像：线性插值  
    float getPixelBI(CvMat * im, float col, float row);//双线性插值函数  
    void normalizeVec(float* vec, int dim);//向量归一化    
    CvMat* GaussianKernel2D(float sigma);  //得到2维高斯核  
    void normalizeMat(CvMat* mat) ;        //矩阵归一化  
    float* GaussianKernel1D(float sigma, int dim) ; //得到1维高斯核  
      
    //在具体像素处宽度方向进行高斯卷积  
    float ConvolveLocWidth(float* kernel, int dim, CvMat * src, int x, int y) ;    
    //在整个图像宽度方向进行1D高斯卷积  
    void Convolve1DWidth(float* kern, int dim, CvMat * src, CvMat * dst) ;         
    //在具体像素处高度方向进行高斯卷积  
    float ConvolveLocHeight(float* kernel, int dim, CvMat * src, int x, int y) ;   
    //在整个图像高度方向进行1D高斯卷积  
    void Convolve1DHeight(float* kern, int dim, CvMat * src, CvMat * dst);       
    //用高斯函数模糊图像    
    int BlurImage(CvMat * src, CvMat * dst, float sigma) ;            
    ```
    
#### 算法核心

本程序中，sift算法被分为以下五个步骤及其相对应的函数（可能表述与上，或与前俩篇文章有所偏差，但都一个意思）：

```c
//SIFT算法第一步：图像预处理  
CvMat *ScaleInitImage(CvMat * im) ;                  //金字塔初始化  
  
//SIFT算法第二步：建立高斯金字塔函数  
ImageOctaves* BuildGaussianOctaves(CvMat * image) ;  //建立高斯金字塔  
  
//SIFT算法第三步：特征点位置检测，最后确定特征点的位置  
int DetectKeypoint(int numoctaves, ImageOctaves *GaussianPyr);  
void DisplayKeypointLocation(IplImage* image, ImageOctaves *GaussianPyr);  
  
//SIFT算法第四步：计算高斯图像的梯度方向和幅值，计算各个特征点的主方向  
void ComputeGrad_DirecandMag(int numoctaves, ImageOctaves *GaussianPyr);  
  
int FindClosestRotationBin (int binCount, float angle);  //进行方向直方图统计  
void AverageWeakBins (double* bins, int binCount);       //对方向直方图滤波  
//确定真正的主方向  
bool InterpolateOrientation (double left, double middle,double right, double *degreeCorrection, double *peakValue);  
//确定各个特征点处的主方向函数  
void AssignTheMainOrientation(int numoctaves, ImageOctaves *GaussianPyr,ImageOctaves *mag_pyr,ImageOctaves *grad_pyr);  
//显示主方向  
void DisplayOrientation (IplImage* image, ImageOctaves *GaussianPyr);  
  
//SIFT算法第五步：抽取各个特征点处的特征描述字  
void ExtractFeatureDescriptors(int numoctaves, ImageOctaves *GaussianPyr);  
  
//为了显示图象金字塔，而作的图像水平、垂直拼接  
CvMat* MosaicHorizen( CvMat* im1, CvMat* im2 );  
CvMat* MosaicVertical( CvMat* im1, CvMat* im2 );  
  
//特征描述点，网格    
#define GridSpacing 4  
```

#### 主体实现
ok，以上所有的工作都就绪以后，那么接下来，咱们就先来编写main函数，因为你一看主函数之后，你就立马能发现sift算法的工作流程及其原理了。

（主函数中涉及到的函数，下一篇文章：[一、教你一步一步用c语言实现sift算法、下](http://blog.csdn.net/v_JULY_v/article/details/6246213)，咱们自会一个一个编写）：

```c
int main( void )  
{  
 //声明当前帧IplImage指针  
 IplImage* src = NULL;   
 IplImage* image1 = NULL;   
 IplImage* grey_im1 = NULL;   
 IplImage* DoubleSizeImage = NULL;  
   
 IplImage* mosaic1 = NULL;   
 IplImage* mosaic2 = NULL;   
   
 CvMat* mosaicHorizen1 = NULL;  
 CvMat* mosaicHorizen2 = NULL;  
 CvMat* mosaicVertical1 = NULL;  
   
 CvMat* image1Mat = NULL;  
 CvMat* tempMat=NULL;  
   
 ImageOctaves *Gaussianpyr;  
 int rows,cols;  
  
#define Im1Mat(ROW,COL) ((float *)(image1Mat->data.fl + image1Mat->step/sizeof(float) *(ROW)))[(COL)]  
   
 //灰度图象像素的数据结构  
#define Im1B(ROW,COL) ((uchar*)(image1->imageData + image1->widthStep*(ROW)))[(COL)*3]  
#define Im1G(ROW,COL) ((uchar*)(image1->imageData + image1->widthStep*(ROW)))[(COL)*3+1]  
#define Im1R(ROW,COL) ((uchar*)(image1->imageData + image1->widthStep*(ROW)))[(COL)*3+2]  
   
 storage = cvCreateMemStorage(0);   
   
 //读取图片  
 if( (src = cvLoadImage( "street1.jpg", 1)) == 0 )  // test1.jpg einstein.pgm back1.bmp  
  return -1;  
  
 //为图像分配内存   
 image1 = cvCreateImage(cvSize(src->width, src->height),  IPL_DEPTH_8U,3);  
 grey_im1 = cvCreateImage(cvSize(src->width, src->height),  IPL_DEPTH_8U,1);  
 DoubleSizeImage = cvCreateImage(cvSize(2*(src->width), 2*(src->height)),  IPL_DEPTH_8U,3);  
  
 //为图像阵列分配内存，假设两幅图像的大小相同，tempMat跟随image1的大小  
 image1Mat = cvCreateMat(src->height, src->width, CV_32FC1);  
 //转化成单通道图像再处理  
 cvCvtColor(src, grey_im1, CV_BGR2GRAY);  
 //转换进入Mat数据结构,图像操作使用的是浮点型操作  
 cvConvert(grey_im1, image1Mat);  
   
 double t = (double)cvGetTickCount();  
 //图像归一化  
 cvConvertScale( image1Mat, image1Mat, 1.0/255, 0 );  
   
 int dim = min(image1Mat->rows, image1Mat->cols);  
 numoctaves = (int) (log((double) dim) / log(2.0)) - 2;    //金字塔阶数  
 numoctaves = min(numoctaves, MAXOCTAVES);  
  
 //SIFT算法第一步，预滤波除噪声，建立金字塔底层  
 tempMat = ScaleInitImage(image1Mat) ;  
 //SIFT算法第二步，建立Guassian金字塔和DOG金字塔  
 Gaussianpyr = BuildGaussianOctaves(tempMat) ;  
   
 t = (double)cvGetTickCount() - t;  
 printf( "the time of build Gaussian pyramid and DOG pyramid is %.1f/n", t/(cvGetTickFrequency()*1000.) );  
   
#define ImLevels(OCTAVE,LEVEL,ROW,COL) ((float *)(Gaussianpyr[(OCTAVE)].Octave[(LEVEL)].Level->data.fl + Gaussianpyr[(OCTAVE)].Octave[(LEVEL)].Level->step/sizeof(float) *(ROW)))[(COL)]  
 //显示高斯金字塔  
 for (int i=0; i<numoctaves;i++)  
 {  
  if (i==0)  
  {  
   mosaicHorizen1=MosaicHorizen( (Gaussianpyr[0].Octave)[0].Level, (Gaussianpyr[0].Octave)[1].Level );  
   for (int j=2;j<SCALESPEROCTAVE+3;j++)  
    mosaicHorizen1=MosaicHorizen( mosaicHorizen1, (Gaussianpyr[0].Octave)[j].Level );  
   for ( j=0;j<NUMSIZE;j++)  
    mosaicHorizen1=halfSizeImage(mosaicHorizen1);  
  }  
  else if (i==1)  
  {  
   mosaicHorizen2=MosaicHorizen( (Gaussianpyr[1].Octave)[0].Level, (Gaussianpyr[1].Octave)[1].Level );  
   for (int j=2;j<SCALESPEROCTAVE+3;j++)  
    mosaicHorizen2=MosaicHorizen( mosaicHorizen2, (Gaussianpyr[1].Octave)[j].Level );  
   for ( j=0;j<NUMSIZE;j++)  
    mosaicHorizen2=halfSizeImage(mosaicHorizen2);  
   mosaicVertical1=MosaicVertical( mosaicHorizen1, mosaicHorizen2 );  
  }  
  else  
  {  
   mosaicHorizen1=MosaicHorizen( (Gaussianpyr[i].Octave)[0].Level, (Gaussianpyr[i].Octave)[1].Level );  
   for (int j=2;j<SCALESPEROCTAVE+3;j++)  
    mosaicHorizen1=MosaicHorizen( mosaicHorizen1, (Gaussianpyr[i].Octave)[j].Level );  
   for ( j=0;j<NUMSIZE;j++)  
    mosaicHorizen1=halfSizeImage(mosaicHorizen1);  
   mosaicVertical1=MosaicVertical( mosaicVertical1, mosaicHorizen1 );  
  }  
 }  
 mosaic1 = cvCreateImage(cvSize(mosaicVertical1->width, mosaicVertical1->height),  IPL_DEPTH_8U,1);  
 cvConvertScale( mosaicVertical1, mosaicVertical1, 255.0, 0 );  
 cvConvertScaleAbs( mosaicVertical1, mosaic1, 1, 0 );  
   
 //  cvSaveImage("GaussianPyramid of me.jpg",mosaic1);  
 cvNamedWindow("mosaic1",1);  
 cvShowImage("mosaic1", mosaic1);  
 cvWaitKey(0);  
 cvDestroyWindow("mosaic1");  
 //显示DOG金字塔  
 for ( i=0; i<numoctaves;i++)  
 {  
  if (i==0)  
  {  
   mosaicHorizen1=MosaicHorizen( (DOGoctaves[0].Octave)[0].Level, (DOGoctaves[0].Octave)[1].Level );  
   for (int j=2;j<SCALESPEROCTAVE+2;j++)  
    mosaicHorizen1=MosaicHorizen( mosaicHorizen1, (DOGoctaves[0].Octave)[j].Level );  
   for ( j=0;j<NUMSIZE;j++)  
    mosaicHorizen1=halfSizeImage(mosaicHorizen1);  
  }  
  else if (i==1)  
  {  
   mosaicHorizen2=MosaicHorizen( (DOGoctaves[1].Octave)[0].Level, (DOGoctaves[1].Octave)[1].Level );  
   for (int j=2;j<SCALESPEROCTAVE+2;j++)  
    mosaicHorizen2=MosaicHorizen( mosaicHorizen2, (DOGoctaves[1].Octave)[j].Level );  
   for ( j=0;j<NUMSIZE;j++)  
    mosaicHorizen2=halfSizeImage(mosaicHorizen2);  
   mosaicVertical1=MosaicVertical( mosaicHorizen1, mosaicHorizen2 );  
  }  
  else  
  {  
   mosaicHorizen1=MosaicHorizen( (DOGoctaves[i].Octave)[0].Level, (DOGoctaves[i].Octave)[1].Level );  
   for (int j=2;j<SCALESPEROCTAVE+2;j++)  
    mosaicHorizen1=MosaicHorizen( mosaicHorizen1, (DOGoctaves[i].Octave)[j].Level );  
   for ( j=0;j<NUMSIZE;j++)  
    mosaicHorizen1=halfSizeImage(mosaicHorizen1);  
   mosaicVertical1=MosaicVertical( mosaicVertical1, mosaicHorizen1 );  
  }  
 }  
 //考虑到DOG金字塔各层图像都会有正负，所以，必须寻找最负的，以将所有图像抬高一个台阶去显示  
 double min_val=0;  
 double max_val=0;  
 cvMinMaxLoc( mosaicVertical1, &min_val, &max_val,NULL, NULL, NULL );  
 if ( min_val<0.0 )  
  cvAddS( mosaicVertical1, cvScalarAll( (-1.0)*min_val ), mosaicVertical1, NULL );  
 mosaic2 = cvCreateImage(cvSize(mosaicVertical1->width, mosaicVertical1->height),  IPL_DEPTH_8U,1);  
 cvConvertScale( mosaicVertical1, mosaicVertical1, 255.0/(max_val-min_val), 0 );  
 cvConvertScaleAbs( mosaicVertical1, mosaic2, 1, 0 );  
   
 //  cvSaveImage("DOGPyramid of me.jpg",mosaic2);  
 cvNamedWindow("mosaic1",1);  
 cvShowImage("mosaic1", mosaic2);  
 cvWaitKey(0);  
   
 //SIFT算法第三步：特征点位置检测，最后确定特征点的位置  
 int keycount=DetectKeypoint(numoctaves, Gaussianpyr);  
 printf("the keypoints number are %d ;/n", keycount);  
 cvCopy(src,image1,NULL);  
 DisplayKeypointLocation( image1 ,Gaussianpyr);  
   
 cvPyrUp( image1, DoubleSizeImage, CV_GAUSSIAN_5x5 );  
 cvNamedWindow("image1",1);  
 cvShowImage("image1", DoubleSizeImage);  
 cvWaitKey(0);    
 cvDestroyWindow("image1");  
   
 //SIFT算法第四步：计算高斯图像的梯度方向和幅值，计算各个特征点的主方向  
 ComputeGrad_DirecandMag(numoctaves, Gaussianpyr);  
 AssignTheMainOrientation( numoctaves, Gaussianpyr,mag_pyr,grad_pyr);  
 cvCopy(src,image1,NULL);  
 DisplayOrientation ( image1, Gaussianpyr);  
   
 //  cvPyrUp( image1, DoubleSizeImage, CV_GAUSSIAN_5x5 );  
 cvNamedWindow("image1",1);  
 //  cvResizeWindow("image1", 2*(image1->width), 2*(image1->height) );  
 cvShowImage("image1", image1);  
 cvWaitKey(0);  
   
 //SIFT算法第五步：抽取各个特征点处的特征描述字  
 ExtractFeatureDescriptors( numoctaves, Gaussianpyr);  
 cvWaitKey(0);  
   
 //销毁窗口  
 cvDestroyWindow("image1");  
 cvDestroyWindow("mosaic1");  
 //释放图像  
 cvReleaseImage(&image1);  
 cvReleaseImage(&grey_im1);  
 cvReleaseImage(&mosaic1);  
 cvReleaseImage(&mosaic2);  
 return 0;  
}  
```

更多见下文：[一、教你一步一步用c语言实现sift算法、下](http://blog.csdn.net/v_JULY_v/article/details/6246213)。本文完。
